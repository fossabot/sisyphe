Abstract
This paper deals with a new feature selection and feature contrasting approach for classification of highly unbalanced textual data with a high degree of similarity between intrinsic classes. An example of such classification context is illustrated by the task of classifying bibliographic references into a patent classification scheme. This task represents one of the domains of investigation of the QUAERO project, with the final goal of helping experts to evaluate upcoming patents through the use of related research.
1 Introduction
Text categorization is a machine learning task which aims at automatically assigning predefined category labels to new upcoming free text documents with related characteristics [COH 05]. Because of its numerous applications, like mail or news filtering [COR 07][PUR 06][EVA 07], emotion detection [PAN 08], text genre analysis [SAL 09], or even patent categorization, text classification has been one of the most studied branches within the field of machine learning [HIL 07]. However, a bunch of classification problems raise new challenges in the domain, especially those ones which implies to deal with imbalanced data and highly similar classes. In the context of text categorization, patents validation assistance takes part in that class. It consists in generating help to experts in their task of evaluation of the novelty of a patent based on the automatic assignation of the most relevant scientific papers related with the classification codes of the said patent. As soon as learning is based on citations extracted from the patents which are usually associated to different level of a hierarchy of classification codes, first, there is no guaranty of a homogeneous distribution of the citations (i.e. the learning examples) among the codes, and, second, there is a high chance to have similar citations in different classes. 
We illustrate in that paper that the exploitation of standard strategies for classification and preprocessing would leads to non exploitable results in that context. We thus propose a new preprocessing alternative as well. The remaining of the paper is structured as follows. Section 2 presents the process we used to generate our experimental resource. Section 3 presents a new feature selection approach suitable to deal with the unsolved class imbalance and class similarities problems. Section 4 compares the results with and without the use of the proposed approach. Section 6 draws our conclusion and perspectives.
2 Dataset generation
Our main experimental resource is issued from the QUAREO1 project. It is a collection of patents related to the pharmacology domain and including bibliographic references. The bibliographic citations in the patents are extracted from the Medline2 database. The source data contains 6387 patents in XML format, grouped into 15 subclasses of the A61K class (medical preparation). 25887 citations have been extracted from 6387 patents [HAJ 12]. Then the Medline database is queried with extracted citations for related scientific articles. The querying gives 7501 articles with 90% recall. Each article is then labeled by the class code of the citing patent. The set of labeled articles represents the final document set on which the training is performed. 
The extracted reference set is converted to a bag of words model [SAL 71] using the TreeTagger tool [SCH 94] developed by the Institute for Computational Linguistics of the University of Stuttgart. In our case, the documents are firstly lemmatized and the tagging process is performed on lemmatized items (in the case when a word is unknown to the lemmatizer, its original form is conserved). The punctuation signs and the numbers identified by the tagger are deleted. 
Every document is finally represented as a term vector filled with term frequencies. The description space generated by the tagger has dimensionality 31214. To reduce noise generated by the TreeTagger tool, a frequency threshold of 45 (i.e. an average threshold of 3/class) is applied on the extracted descriptors. It resulted in a thresholded description space of dimensionality 1804. Finally, the exploitation of the Term Frequency-Inverse Document Frequency (TF‑IDF) weighting scheme [SAL 88] provides a sparse matrix representation of the text collection.
Fig. 1. Distribution of training data in patents classes 
(patents-cited articles-descriptors).
Figure 1 highlight the highly imbalanced distribution of both, patents, extracted references and keywords associated with references relatively to the different class codes. As an example, smallest class contains only 22 extracted references (A61K41 class) whilst the bigger one has more than 2500 (A61K31 class).
The exploitation of resampling techniques [KUB 97] as well as the one of standard feature selection techniques [FOR 03] could be envisaged to compensate influence of the bigger classes. However, in our context, the ability of such techniques to precisely detect the right class is curtailed by the high class to class similarity due to the association of the initial patents to a specialized branch of the patent classification: inter-class similarity computed using cosine correlation between class profiles generated by the descriptors issued from the extracted bibliographical references indicates that more than 70% of classes' couples have a similarity between 0.5 and 0.9. 
As an alternative, we thus propose a new filter approach which relies on the exploitation of a class quality measure based on specific feature maximization metric. Such metric has already demonstrated significant potential in the framework of unsupervised learning, as for example for unsupervised classification of French verbs on the basis of syntactic features [FAL 12].
3 Feature maximization based selection
Let us consider a set of clusters C resulting from a clustering method applied on a set of data D represented with a set of descriptive features F, feature maximization is a metric which favors clusters with maximum Feature F-measure. The Feature F-measure  of a feature f associated to a cluster c is defined as the harmonic mean of Feature Recall and Feature Precision  indexes which in turn are defined as:
where represents the weight of the feature f for data d and Fc represent the set of features occurring in the data associated to the cluster c. 
Taking into consideration the basic definition of feature maximization metric presented above, the feature maximization-based selection process can thus be defined as a parameter-free class-based process in which a class feature is characterized using both its capacity to discriminate a given class from the others ( index) and its capacity to accurately represent the class data ( index). The set Sc of features that are characteristic of a given class c belonging to an overall class set C results in:
    
where 
and  .
with C/f representing the restriction of the set C to the classes in which the feature f is present.
Features that are judged relevant for a given class are the features whose representation is altogether better than their average representation in all the classes including those features and better than the average representation of all the features, as regard to the feature F-measure metric. 
In the specific framework of the feature maximization process, a contrast enhancement step can be exploited complementary to the former feature selection step. The role of this step is to fit the description of each data to the specific characteristics of its associated class which have been formerly highlighted by the feature selection step. In the case of our metric, it consists in modifying the weighting scheme of the data specifically to each class by taking into consideration the "information gain" provided by the Feature F-measures of the features, locally to that class. For a feature c belonging to the set of selected features SC of a class C, the gain CFc can be defined as:
4 Experiments and results
To perform our experiments we firstly take into consideration different classification algorithms which are implemented in the Weka toolkit3: J48 Decision Tree algorithm [QUI 93], Random Forest algorithm [BRE 01] (RF), KNN algorithm [AHA 91], DMNBtext Bayesian Network algorithm [SU 08] (DMT) and SMO-SVM algorithm [PLA 98].
Most of these algorithms are general purpose classification algorithms, except from DMNBtext which is a Discriminative Multinomial Naive Bayes classifier especially developed for text classification. As compared to classical Multinomial Naive Bayes classifier this algorithm cumulates the computational efficiency of Naive Bayes approaches and the accuracy of Discriminating approaches by taking into account both the likelihood and the classification objectives during the frequency counting. Other general purpose algorithms whose accuracy has especially been reported for text classification are SMO and KNN [ZHA 01]. Default parameters are used when executing these algorithms, except for KNN for which the number of neighbors is optimized based on resulting accuracy.
We then more especially focus on testing the efficiency of the feature selection approaches including our new proposal (FMC). We include in our test a panel of filter approaches which are computationally tractable with high dimensional data4, making again use of their Weka toolkit implementation. The panel of tested methods includes: Chi-square selector [LAD 11], Information gain selector |HAL 99b], CBF subset selector [DAS 03] (CB), Symmetrical Uncertainty selector [YUL 03], ReliefF selector [KON 94] (RF) and Principal Component Analysis selector [PER 01] (PCA). Defaults parameters are also used for most this methods, except for PCA for which the percentage of explained variance is tuned based on resulting accuracy. 10-fold cross validation is used on all our experiments.
The different results are reported in Tables 1 to 4 and in Figure 2 to 3. Tables and figures present standard performance measures (True Positive Rate (TP) or Precision, False Positive Rate (FP), Recall (R), F-measure (F) and ROC) weighted by class sizes and averaged over all classes. For each table, and each combination of selection and classification methods, a performance increase indicator is computed using the DMNBtext True Positive results on the original data as the reference. Finally, as soon as the results are identical for Chi-square, Information Gain and Symmetrical Uncertainty, they are thus reported only once in the tables as Chi-square results (and noted CHI+).
Table 1 highlights that performance of all classification methods are low on the considered dataset if no feature selection process is performed. They also confirm the superiority of the DMNBtext, SMO and KNN methods on the two other tree-based methods in that context. Additionally, DMNBtext provides the best overall performance in terms of discrimination as it is illustrated by its highest ROC value. However, as it is also shown by confusion matrix of figure 2, the method is clearly not exploitable in an operational patent evaluation context, because of its high confusion between classes mainly due to its incapacity to cope with the very important data attraction effect of the biggest class.
Whenever a usual feature selection process is performed in combination with the best method, that is DMNBtext method, the exploitation of the usual feature selection strategies slightly alters the quality of the results, instead of bringing up an added value, as it is shown in Table 1. Alternatively, same table highlights that the feature reduction of F-max selection method is similar to Chi-square and its combination with F-max data description contrasting boosts the performance of the classification method (+81%), leading to excellent classification results (Accuracy of 0.96) in a very complex classification context.

Table 4. Class data and F-max selected features/class.
Table 2 and figures 1-2 illustrate the capabilities of the F-max approach to efficiently cope with the class imbalance problem. Hence, examination of both TP rate changes (especially in small classes) in table 4 and confusion matrices of figures 1-2 shows that the data attraction effect of the majority class that occurs at a high level in the case of the exploitation of the original data (figure 1) is quite completely overcome whenever the F-max approach is exploited (figure 2). The capability of the approach to correct class imbalance is also clearly highlighted by the homogeneous distribution of the selected features in the classes it provides, despite of their very different sizes (table 4).
Figure 2. Confusion matrix of the optimal results before feature selection (Classification: DMNBtext).
Figure 1. Confusion matrix of the optimal results after feature selection
(Classification: DMNBtext – Feature selection: FMC)
5 Conclusion
Feature maximization is a cluster quality metric which favors clusters with maximum feature representation as regard to their associated data. In this paper, we have proposed a straightforward adaptation of such metric, which has already demonstrated several generic advantages in the framework of unsupervised learning, to the context of supervised classification. Our main goal was to build up an efficient feature selection and feature contrasting model that could overcome the usual problems arising in the supervised classification of large volume of data, and more especially in that of large full text data. These problems relate to classes imbalance, high dimensionality, noise, and high degree of similarity between classes. Through our experiments on a large dataset constituted of bibliographical records extracted from a patents classification, we more especially showed that our approach can naturally cope with the said handicaps, significantly enhance the performance of classification methods (+80%). Another important advantage of this technique is that it is a parameter-free approach and it can thus be used in a larger scope, like in the one of semi-supervised learning.
References 
[AHA 91] Aha, D. & D. Kibler (1991). Instance-based learning algorithms. Machine Learning. 6:37-66.
 [BRE 01] Breiman, L. (October 2001). Random forests. Machine Learning 45(1), 5–32.
 [COH 05] Cohen, A.M. & Hersh, W.R. (2005). A survey of current work in biomedical text mining. Briefings in Bioinformatics 6. pp. 57-71.
 [COR 07] Cormack, G.V. & Lynam, T.R. (2007). Online supervised spam filter evaluation. ACM Transactions on Information Systems. 25(3):11.
 [DAS 03] Dash, M. & H. Liu (2003). Consistency-based search in feature selection. Artificial Intelligence 151, nᵒ 1 (2003): 155-176.
 [EVA 07] Evans, M., McIntosh, W., Lin, J. & Cates, C.: Recounting the courts? Applying automated content analysis to enhance empirical legal research. Journal of Empirical Legal Studies. 4(4):1007–1039.
[FAL 12] Falk, I., C. Gardent & J.-C. Lamirel (2012). Classifying French Verbs using French and English Lexical Resources Proceedings of ACL 2012. Jeju Island Korea, July 2012.
[FOR 03] Forman, G. (2003). An extensive empirical study of feature selection metrics for text classification. The Journal of Machine Learning Research 3 (2003): 1289–1305.
[HAJ 12] Hajlaoui, K., Cuxac, P., Lamirel, J.C., François C. (2012). Enhancing Patent Expertise through Automatic Matching with Scientific Papers. Discovery Science 2012: 299-312
 [HAL 99] Hall, M.A. & L.A. Smith (1999). Feature Selection for Machine Learning: Comparing a Correlation-Based Filter Approach to the Wrapper. In Proceedings of the Twelfth International Florida Artificial Intelligence Research Society Conference, 235–239. AAAI Press.
[HIL 07] Hillard, D. Purpura, S. & Wilkerson, J. (2007). An active learning framework for classifying political text. In Annual Meeting of the Midwest Political Science Association. Chicago.
 [KON 94] Kononenko, I. (1994). Estimating Attributes: Analysis and Extensions of RELIEF. In: European Conference on Machine Learning, pp 171-182.
[KUB 97] Kubat, M. and Matwin, S. (1997). Addressing the curse of imbalanced training sets: one-sided selection. In ICML, pp. 179-186, 1997.
[LAD 11] Ladha, L. & T. Deepa (2011). Feature selection methods and algorithms. International Journal on Computer Science and Engineering, 3, nᵒ 5 (2011): 1787–1797.
 [PAN 08] Pang, B. et Lee, L.: Opinion mining and sentiment analysis. Foundations and Trends in Information Retrieval. 2(1-2):1–135.
 [PER 01] Pearson, K. (1901). "On Lines and Planes of Closest Fit to Systems of Points in Space". Philosophical Magazine 2 (11): 559–572.
[PLA 98] Platt, J. (1998). Sequential Minimal Optimization: A Fast Algorithm for Training Support Vector Machines.
[PUR 06] Purpura, S. and Hillard, D. (2006).  Automated classification of congressional legislation. Proceedings of the international conference on Digital government research, pp. 219–225, 2006.
[QUI 93] Quinlan, R. (1993). C4.5: Programs for Machine Learning. San Mateo, CA: Morgan Kaufmann.
 [SAL 71] Salton, G. (1971). Automatic processing of foreign language documents. Prentice-Hill: Englewood, Cliffs, NJ.
[SAL 88] Salton, G. & C. Buckley (1988). Term weighting approaches in automatic text retrieval. Information Processing and Management 24(5), 513–523.
[SAL 09]  Salager-Meyer F. (2009). Discoursal flaws in medical english abstracts: a genre analysis per research- and text-type, Interdisciplinary Journal for the Study of Discourse, 10 (4),: 365-384
[SCH 94] Schmid, H. (1994). Probabilistic part-of-speech tagging using decision trees. Proceedings of International Conference on New Methods in Language Processing.
 [SU 08] Su, J., H. Zhang, C. Ling, & S. Matwin (2008). Discriminative parameter learning for bayesian networks. ICML.
 [YUL 03] Yu, L. & H. Liu, (2003). Feature Selection for High-Dimensional Data: A Fast Correlation-Based Filter Solution. ICML 2003, 856-863, August 21-24, 2003, Washington DC, USA.
[ZHA 01] T. Zhang and F. J. Oles. Text categorization based on regularized linear classification methods. Inf. Retr., 4(1):5–31.
